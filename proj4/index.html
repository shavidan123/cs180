<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Image Warping and Mosaicing</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <h1>Image Warping and Mosaicing</h1>
        <p>CS 180: Project 4, Part A<br>Avidan Shah</p>
    </header>

    <main>
        <section>
            <h2>Part 1: Shoot and Digitize Pictures</h2>
            <p>
                All images were captured using my iPhone camera. Note that for the picture of my room, there is a crease on the wall that should not be mistaken for a crease resulting from mosaicing.
            </p>
            <div class="image-row">
                <figure>
                    <img src="./images/strawberrycrisps.jpg" alt="Crisps Image 1">
                    <figcaption>First view of the strawberry crisps.</figcaption>
                </figure>
                <figure>
                    <img src="./images/strawberrycrisps2.jpg" alt="Crisps Image 2">
                    <figcaption>Alternate view of the strawberry crisps that I wanted to warp to.</figcaption>
                </figure>
            </div>
            <div class="image-row">
                <figure>
                    <img src="./images/computerpic1.jpg" alt="Laptop Image 1">
                    <figcaption>First image of the laptop setup.</figcaption>
                </figure>
                <figure>
                    <img src="./images/computerpic2.jpg" alt="Laptop Image 2">
                    <figcaption>Alternate view of the laptop setup (that I wanted to warp to).</figcaption>
                </figure>
            </div>
        </section>

        <section>
            <h2>Part 2: Recover Homographies</h2>
            <p>
                The homography matrix is a transformation matrix that maps corresponding points between two images, enabling operations like perspective warping. It has 8 independent parameters, as the matrix entries are determined up to scale, with the bottom-right entry fixed to 1 to avoid ambiguity. This matrix captures transformations such as rotation, translation, scaling, and skewing.
                To compute the homography matrix, I manually identified at least four pairs of corresponding points between the two images. These point correspondences define the relationship between the two views. Using equations covered in lecture, I set up a system of linear equations that expresses the coordinates of the corresponding points through the unknown homography matrix. I solved this system using least squares optimization to minimize error, ensuring the matrix accurately represents the transformation, even when there are small discrepancies in the selected points.
            </p>
            <figure>
                <img src="./images/homography.png" alt="Homography Representation">
                <figcaption>Visualization of the homography matrix.</figcaption>
            </figure>
        </section>

        <section>
            <h2>Part 3: Image Rectification</h2>
            <p>
                I began by transforming the corners of the original image using the homography matrix. This involved multiplying the homography matrix with the corner coordinates, expressed in homogeneous form, and then normalizing the resulting points to convert them back. These warped corner points defined the new boundaries of the transformed image.
                Next, I calculated the spatial bounds of the warped image by finding the minimum and maximum coordinates from the transformed corners. With these bounds, I created a grid of coordinates (using a meshgrid) that corresponds to every pixel location in the new warped image.        
                For each pixel in this new coordinate grid, I mapped it back to the original image using the inverse of the homography transformation. I applied nearest-neighbor interpolation to determine the pixel values from the corresponding points in the original image. Any pixel locations that did not map to valid points in the original image were filled with a value of 0, ensuring that the final warped image was complete and handled any gaps gracefully.
            </p>
            <figure>
                <img src="./images/crispspoints.png" alt="Crisps Point Correspondences">
                <figcaption>Point correspondences for the strawberry crisps image.</figcaption>
            </figure>
            <figure>
                <img src="./images/zoomedcrisps.png" alt="Zoomed View of Warped Crisps">
                <figcaption>Zoomed-in view of the warped strawberry crisps image.</figcaption>
            </figure>
            <figure>
                <img src="./results/rectified_crisps.png" alt="Rectified Crisps Image">
                <figcaption>Rectified image of the crisps.</figcaption>
            </figure>
            <figure>
                <img src="./images/computerpoints.png" alt="Laptop Point Correspondences">
                <figcaption>Point correspondences for the laptop image.</figcaption>
            </figure>
            <figure>
                <img src="./results/rectified_laptop.png" alt="Rectified Laptop Image">
                <figcaption>Rectified image of the laptop setup (zoomed in).</figcaption>
            </figure>
        </section>

        <section>
            <h2>Part 4: Blend Images into a Mosaic</h2>
            <p>
                For each mosaic, I left one image in its original form and warped the other to align with the same perspective, ensuring they shared a common coordinate system. To achieve smooth transitions in the overlapping areas, I applied weighted averaging with a gradient mask, allowing for a gradual blend between the two images to minimize visible seams. I utilized Gaussian and Laplacian stacks to separate the images into multiple frequency components. The Gaussian stacks captured the low-frequency components—broad color transitions and general shapes—while the Laplacian stacks isolated the high-frequency details, such as edges and fine textures. At each level of the stack, I blended the corresponding components from both images using the gradient mask. The low-frequency Gaussian components ensured smooth blending across large areas, while the high-frequency Laplacian components preserved critical edges and finer details. Finally, I combined the blended components from all stack levels to produce the complete mosaic. Note that in the picture of my room, there is a crease in the wall, not due to the mosaic.
            </p>
            <div class="image-grid">
                <figure>
                    <img src="./images/roomperspective1.jpg" alt="Room Image 1">
                    <figcaption>First perspective of my room.</figcaption>
                </figure>
                <figure>
                    <img src="./images/roomperspective2.jpg" alt="Room Image 2">
                    <figcaption>Second perspective of my room.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_room_perspective.png" alt="Mosaic of Room">
                    <figcaption>Mosaic of the room.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlk1.jpg" alt="MLK Image 1">
                    <figcaption>First perspective of the inside of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlk2.jpg" alt="MLK Image 2">
                    <figcaption>Second perspective of the inside of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_mlk.png" alt="Mosaic of MLK Statue">
                    <figcaption>Mosaic of the MLK pictures.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlkalt1.jpg" alt="Alternate MLK Image 1">
                    <figcaption>Alternate perspective of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlkalt2.jpg" alt="Alternate MLK Image 2">
                    <figcaption>Picture 2 of alternate perspective of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_mlkalt.png" alt="Alternate Mosaic of MLK">
                    <figcaption>Final Mosaic of the two previous images.</figcaption>
                </figure>
            </div>
        </section>
        <section>
            <h2>Project 4B: Feature Detection and Matching</h2>
            <p>
                In this part, I implemented feature detection, feature description, and feature matching to identify corresponding points between images. This involved detecting Harris corners, applying Adaptive Non-Maximal Suppression (ANMS), extracting feature descriptors, and matching features using a robust 4 Point RANSAC-based homography estimation.
            </p>

            <h3>Harris Corner Detection Results</h3>
            <div class="image-row">
                <figure>
                    <img src="./results/harris_mlk_1.png" alt="Harris Corners on MLK Image 1">
                    <figcaption>Harris corners on MLK Image 1.</figcaption>
                </figure>
                <figure>
                    <img src="./results/harris_mlk_2.png" alt="Harris Corners on MLK Image 2">
                    <figcaption>Harris corners on MLK Image 2.</figcaption>
                </figure>
            </div>

            <h3>Adaptive Non-Maximal Suppression (ANMS)</h3>
            <div class="image-row">
                <figure>
                    <img src="./results/anms_mlk_1.png" alt="ANMS Corners on MLK Image 1">
                    <figcaption>ANMS corners on MLK Image 1.</figcaption>
                </figure>
                <figure>
                    <img src="./results/anms_mlk_2.png" alt="ANMS Corners on MLK Image 2">
                    <figcaption>ANMS corners on MLK Image 2.</figcaption>
                </figure>
            </div>

            <h3>Feature Descriptor Extraction and Feature Matching</h3>
            <p>
                For each detected corner, I extracted an axis-aligned 8x8 feature descriptor from a 40x40 window around the keypoint. These descriptors were normalized to ensure robustness against lighting variations.
                I then matched feature descriptors between the two MLK images using the ratio test. This involved comparing the distance of the closest neighbor to the second-closest neighbor and selecting matches where this ratio was below a certain threshold, indicating reliable correspondences. Figure 6B from the paper helped choose the correct threshold
            </p>
            <figure>
                <img src="./results/matches_mlk.png" alt="Feature Matches between MLK Images">
                <figcaption>Feature matches between MLK Image 1 and MLK Image 2.</figcaption>
            </figure>
        </section>

        <section>
            <h2>Project 4B: Robust Homography Estimation using RANSAC</h2>
            <p>
                To ensure that the homography estimation was robust to outliers, I implemented the RANSAC algorithm. This involved randomly selecting subsets of correspondences, computing homography matrices, and selecting the matrix with the most inliers based on a predefined threshold. The final homography was refined using all inliers to achieve accurate alignment.
            </p>
            <figure>
                <img src="./results/ransac_mlk.png" alt="RANSAC Inlier Matches">
                <figcaption>Inlier matches identified by RANSAC for MLK images.</figcaption>
            </figure>
            <figure></figure>
                <img src="./results/mlkalt_ransac.png" alt="RANSAC Inlier Matches">
                <figcaption>Inlier matches identified by RANSAC for the alternative MLK images.</figcaption>
            </figure>
        </section>

        <section>
            <h2>Project 4B: RANSAC Based Image Blending and Mosaic Creation</h2>
            <p>
                Using the RANSAC computed homographies, I warped images to a common perspective and blended them to create seamless mosaics. Just as before blending was achieved through weighted averaging and frequency separation using Gaussian and Laplacian stacks, ensuring smooth transitions and preservation of fine details. It seems that there's little difference between the manual mosaics and the ransac generated ones, highlighting the power of autostitching.
            </p>
            <div class="image-grid">
                <!-- MLK Mosaics -->
                <figure>
                    <img src="./images/mlk1.jpg" alt="MLK Image 1">
                    <figcaption>First perspective of the inside of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlk2.jpg" alt="MLK Image 2">
                    <figcaption>Second perspective of the inside of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_mlk.png" alt="Manual Mosaic of MLK">
                    <figcaption>Manual Mosaic of the MLK images.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mlk_mosaic_ransac.jpg" alt="RANSAC Mosaic of MLK">
                    <figcaption>RANSAC-based Mosaic of the MLK images.</figcaption>
                </figure>

                <!-- Alternate MLK Mosaics -->
                <figure>
                    <img src="./images/mlkalt1.jpg" alt="Alternate MLK Image 1">
                    <figcaption>Alternate perspective of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./images/mlkalt2.jpg" alt="Alternate MLK Image 2">
                    <figcaption>Picture 2 of alternate perspective of MLK.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_mlkalt.png" alt="Manual Mosaic of Alternate MLK">
                    <figcaption>Manual Mosaic of the alternate MLK images.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mlkalt_ransac_mosaic.jpg" alt="RANSAC Mosaic of Alternate MLK">
                    <figcaption>RANSAC-based Mosaic of the alternate MLK images.</figcaption>
                </figure>

                <!-- Room Mosaics -->
                <figure>
                    <img src="./images/roomperspective1.jpg" alt="Room Image 1">
                    <figcaption>First perspective of my room.</figcaption>
                </figure>
                <figure>
                    <img src="./images/roomperspective2.jpg" alt="Room Image 2">
                    <figcaption>Second perspective of my room.</figcaption>
                </figure>
                <figure>
                    <img src="./results/mosaic_room_perspective.png" alt="Manual Mosaic of Room">
                    <figcaption>Manual Mosaic of the room images.</figcaption>
                </figure>
                <figure>
                    <img src="./results/room_ransac_mosaic.jpg" alt="RANSAC Mosaic of Room">
                    <figcaption>RANSAC-based Mosaic of the room images.</figcaption>
                </figure>
            </div>
        </section>

        <!-- Conclusion Section -->

        <section>
            <h2>What Have I Learned?</h2>
            <p>
                One of the coolest things I learned from this project is the power of RANSAC in robustly estimating transformation models like homographies. By effectively handling outliers, RANSAC ensures accurate alignment even when a significant portion of the data is noisy or mismatched. Additionally, implementing feature detection and matching deepened my understanding of computer vision techniques and the intricacies involved in creating seamless image mosaics.
            </p>
        </section>

    </main>

</body>
</html>
